{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('5min_data.csv',encoding=\"gb2312\")\n",
    "data.columns=['date','open','high','low','close','volumn']  \n",
    "data = pd.DataFrame(data,columns=['open','high','low','close','volumn'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征数量\n",
    "features_num = len(data.columns) - 1\n",
    "# 定义观察时间窗口120/170/220/270\n",
    "observe_time = 120\n",
    "# 定义预测时间窗口5/10/15\n",
    "predict_time = 5\n",
    "# 一组时间窗口\n",
    "group_time = observe_time + predict_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割特征及标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,returns = list(),list()\n",
    "for i in range(len(data.close)-group_time):\n",
    "    features.append(np.array(data[i:i+observe_time]))\n",
    "    returns.append(data.close[i+group_time]-data.close[i+observe_time])\n",
    "features = np.array(features)\n",
    "returns = np.array(returns)\n",
    "print(features.shape,returns.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "train_length = int(len(features)*alpha)\n",
    "\n",
    "train_data = features[:train_length]\n",
    "test_data = features[train_length:]\n",
    "\n",
    "train_return = returns[:train_length]\n",
    "test_return = returns[train_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据收益率实现三分类打标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(features,returns,per):\n",
    "    neg_list,pos_list,mid_list = list(),list(),list()\n",
    "    neg_value = round(float(sorted(returns)[int(len(returns)*per):int(len(returns)*per)+1][0]),2)\n",
    "    pos_value = round(float(sorted(returns)[int(len(returns)*(1-per)):int(len(returns)*(1-per))+1][0]),2)\n",
    "    mid_left_value = round(float(sorted(returns)[int(len(returns)*(0.5*(1-per))):int((len(returns)*(0.5*(1-per))))+1][0]),2)\n",
    "    mid_right_value = round(float(sorted(returns)[int(len(returns)*(0.5*(1+per))):int((len(returns)*(0.5*(1+per))))+1][0]),2)\n",
    "    print('正样本最小值:%.2f\\t中样本范围:%.2f~%.2f\\t负样本最大值:%.2f'%(pos_value,mid_left_value,mid_right_value,neg_value))\n",
    "    data_x = list()\n",
    "    data_y = list()\n",
    "    for i in range(len(returns)):\n",
    "        if returns[i]<=neg_value:\n",
    "            data_x.append(features[i])\n",
    "            data_y.append(0)\n",
    "        elif mid_left_value<=returns[i]<=mid_right_value:\n",
    "            data_x.append(features[i])\n",
    "            data_y.append(1)            \n",
    "        elif returns[i]>=pos_value:\n",
    "            data_x.append(features[i])\n",
    "            data_y.append(2)\n",
    "        else:\n",
    "            continue\n",
    "    data_x = np.array(data_x)\n",
    "    data_y = np.array(data_y)\n",
    "    data_x = data_x.reshape(data_x.shape[0],data_x.shape[1],data_x.shape[2],1)\n",
    "#     data_y = data_y.reshape(data_y.shape[0],1)\n",
    "    return data_x,data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y = segmentation(train_data,train_return,per=0.1)\n",
    "print(train_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x,test_y = segmentation(test_data,test_return,per=0.1)\n",
    "print(test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(input_shape=(train_x.shape[1], train_x.shape[2], train_x.shape[3]),\n",
    "                        filters=32, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "                       activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(input_shape=(train_x.shape[1], train_x.shape[2], train_x.shape[3]),\n",
    "                        filters=16, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "                       activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             # loss=keras.losses.CategoricalCrossentropy(),  # 需要使用to_categorical\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y, batch_size=64, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'valivation'], loc='upper left')\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
